.TH WIKIASSOC "1" "December 2010"
.SH NAME
Wikiassoc \- generate associative thesaurus from MediaWiki database dump
.SH SYNOPSIS
.B wikiassoc
[\fB-e\fR \fIRE\fR] [\fB-n\fR \fIN\fR] [\fB-qw\fR] \fIpagedump\fR \fIlinkdump\fR
.SH DESCRIPTION
Wikiassoc creates an associative thesaurus,
a mapping from concepts to related concepts,
by analyzing the link structure of a MediaWiki-based wiki,
such as the Wikipedia.
It does so by computing the
.I pf-ibf
statistic for each pair of articles; see the section
.BR REFERENCES ,
below.
An article is defined as a page in namespace 0,
so discussion pages and meta-pages are not taken into account.
.PP
Wikiassoc requires two files to run: a
.I pagedump
and a
.IR linkdump .
For the Wikipedia, these files can be obtained from
.BR http://download.wikimedia.org .
Both files may be compressed using
.BR gzip (1)
or
.BR bzip2 (1).
.PP
Wikiassoc will generate output on stdout
and log information on stderr.
Since Wikiassoc produces large amounts of output,
it may be advisable to redirect stdout to a
.BR gzip (1)
or
.BR bzip2 (1)
pipe.
.PP
Wikiassoc produces stanzas consisting of a term (article title)
starting at the beginning of a line,
followed by the associated terms,
on a line starting with some amount of whitespace.
Note that MediaWiki titles are not allowed to contain whitespace;
they contain underscores
.RB ( _ )
instead.
.SH OPTIONS
.TP
.BI \-e\  RE
Exclude terms/titles matching the regular expression
.I RE
in the output phase.
Such terms are still used in the
.I pf\-ibf
computation.
The regular expression syntax is a subset of that of Perl; see
.BR perlre (1).
.TP
.BI \-n\  N
Generate max. \fIN\fR associations per term/article, default 10.
Some (sparsely linked) terms may have fewer associations.
.TP
.B \-q
Quiet mode, no logging info (except in the case of failure).
.TP
.B \-w
Output numeric weights per association.
Weights are non-normalized
.I pf\-ibf
values, mostly useful for debugging purposes.
.SH ENVIRONMENT
If Wikiassoc was built with multithreading support
(enabled by default if the compiler supports OpenMP),
the number of threads used is controlled by the environment variable
.BR OMP_NUM_THREADS .
.SH NOTES
Generating an associative thesaurus from the larger Wikipedias
may take up to several hours of computing time
and several gigabytes of memory
(one hour and twenty minutes, 12GB
for the Dutch Wikipedia dump of November 2010
on a single 3GHz AMD Opteron processor core).
.SH REFERENCES
.LP
K. Nakayama, T. Hara and S. Nishio (2007).
Wikipedia Mining for an Association Web Thesaurus Construction.
In
.IR "Proc. Int'l Conf. on Web Information Systems Engineering (WISE)" ,
pp. 322-334.
.SH BUGS
Wikiassoc ignores redirect pages.
The output format is big and clunky;
something more compact should be implemented instead.
RDF output would be nice as well.
.SH AUTHOR
Lars Buitinck, University of Groningen.
